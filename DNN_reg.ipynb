{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cooperative-polls",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "following-powder",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "solar-router",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0. 0. 0. 3. 0. 0. 0. 0. 0. 0.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 2. 0.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[0. 1. 0. 0. 0. 0. 0. 3. 0. 0.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[0. 0. 0. 0. 0. 0. 3. 0. 0. 0.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 0. 2.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0. 0. 4. 0. 0. 0. 0. 0. 0. 0.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3  4  5  6  7  8  9                            label\n",
       "0      3  3  3  3  3  3  3  3  3  3  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
       "1      3  2  1  0  3  2  1  0  0  0  [0. 0. 0. 3. 0. 0. 0. 0. 0. 0.]\n",
       "2      3  3  3  3  3  3  3  3  3  3  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
       "3      3  3  3  3  3  3  3  3  3  3  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
       "4      1  2  3  3  3  3  3  3  3  3  [0. 0. 0. 0. 0. 0. 0. 0. 2. 0.]\n",
       "...   .. .. .. .. .. .. .. .. .. ..                              ...\n",
       "99995  1  1  1  1  2  3  0  1  2  3  [0. 1. 0. 0. 0. 0. 0. 3. 0. 0.]\n",
       "99996  3  2  1  0  3  3  3  3  3  3  [0. 0. 0. 0. 0. 0. 3. 0. 0. 0.]\n",
       "99997  0  0  0  0  0  0  0  0  0  0  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
       "99998  1  3  3  3  3  3  3  3  3  3  [0. 0. 0. 0. 0. 0. 0. 0. 0. 2.]\n",
       "99999  0  3  2  1  0  3  2  1  0  0  [0. 0. 4. 0. 0. 0. 0. 0. 0. 0.]\n",
       "\n",
       "[100000 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"artificial_dataset.csv\")\n",
    "data = data.drop(\"Unnamed: 0\", axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "leading-possession",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data points:\t 100000\n",
      "No errors in :\t 66948\n",
      "0 error to keep(1/4 with error):\t 8263\n"
     ]
    }
   ],
   "source": [
    "# parse label's str to bit list\n",
    "y=data['label']  # Labels\n",
    "y_parse = []\n",
    "for n,i in enumerate(y):\n",
    "    y_parse.append([float(j) for j in i.strip(\"[\").strip(\"]\").strip(\"\\n\").strip(\".\").split(\" \")])\n",
    "    \n",
    "nzero_error = 0    \n",
    "for row in y_parse:\n",
    "    if all([r<0.1 for r in row]):\n",
    "        nzero_error += 1\n",
    "        \n",
    "print(\"Data points:\\t\", len(y_parse))\n",
    "print(\"No errors in :\\t\", nzero_error)\n",
    "nkeep = int(((len(y_parse)-nzero_error)/4))\n",
    "print(\"0 error to keep(1/4 with error):\\t\", nkeep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "broken-inspection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all zero's data\n",
    "dr = []\n",
    "yy = []\n",
    "kept_0 = 0\n",
    "for n,row in enumerate(y_parse):\n",
    "    if all([r<0.1 for r in row]):\n",
    "        #if kept_0 < nkeep:\n",
    "        #    yy.append([int(r) for r in row])\n",
    "        #    kept_0 += 1\n",
    "        #else:\n",
    "        dr.append(n)\n",
    "    else:\n",
    "        yy.append([int(r) for r in row])\n",
    "        #yy.append(np.sum([bit*2**h for h, bit in enumerate(row)]))\n",
    "data = data.drop(data.index[dr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cardiovascular-explosion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data head\n",
      "       0  1  2  3  4  5  6  7  8  9                           label\n",
      "64146  3  0  1  2  3  0  1  2  3  0  [0, 4, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "354    3  2  1  0  3  3  3  3  3  3  [0, 0, 0, 0, 0, 3, 0, 0, 0, 0]\n",
      "12081  1  2  3  0  1  2  3  0  0  0  [0, 0, 2, 0, 0, 0, 0, 0, 0, 0]\n",
      "88221  1  2  3  0  1  2  3  0  1  2  [2, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "99172  1  0  0  0  0  0  0  0  0  0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "\n",
      " train data: 23136\n",
      " test data: 9916\n"
     ]
    }
   ],
   "source": [
    "# shuffling data\n",
    "data[\"label\"] = yy\n",
    "data = data.sample(frac=1)\n",
    "print(\"Data head\")\n",
    "print(data.head())\n",
    "X, Y = data.iloc[:,:-1], data[\"label\"]\n",
    "\n",
    "# converting lists to array\n",
    "y = np.zeros((len(Y), 10))\n",
    "for n,i in enumerate(Y):\n",
    "    y[n,:] = i\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "print(\"\\n train data:\", len(X_train))\n",
    "print(\" test data:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "israeli-ministry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization layer\n",
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(np.array(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "bridal-construction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.ylim([0, 10])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error [MSE]')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-daniel",
   "metadata": {},
   "source": [
    "# DeepNeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "killing-spine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_model(norm):\n",
    "    model = keras.Sequential([\n",
    "        norm,\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(20, activation='relu'),\n",
    "        layers.Dense(10, activation='relu'),\n",
    "        layers.Dense(10, activation='relu')\n",
    "    ])\n",
    "    model.compile(loss='mse',\n",
    "                  optimizer=tf.keras.optimizers.Nadam())\n",
    "                  #optimizer=tf.keras.optimizers.Adam(0.002))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "packed-latex",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizatio  (None, 10)               21        \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 64)                704       \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 20)                1300      \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,345\n",
      "Trainable params: 2,324\n",
      "Non-trainable params: 21\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dnn_model = build_and_compile_model(normalizer)\n",
    "dnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "raised-quantum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "579/579 [==============================] - 6s 8ms/step - loss: 0.6431 - val_loss: 0.5384\n",
      "Epoch 2/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.4987 - val_loss: 0.4836\n",
      "Epoch 3/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.4473 - val_loss: 0.4336\n",
      "Epoch 4/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.4055 - val_loss: 0.3963\n",
      "Epoch 5/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3829 - val_loss: 0.3882\n",
      "Epoch 6/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3744 - val_loss: 0.3818\n",
      "Epoch 7/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3693 - val_loss: 0.3803\n",
      "Epoch 8/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.3647 - val_loss: 0.3764\n",
      "Epoch 9/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3620 - val_loss: 0.3755\n",
      "Epoch 10/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3592 - val_loss: 0.3750\n",
      "Epoch 11/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3579 - val_loss: 0.3739\n",
      "Epoch 12/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.3560 - val_loss: 0.3709\n",
      "Epoch 13/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3541 - val_loss: 0.3710\n",
      "Epoch 14/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3530 - val_loss: 0.3703\n",
      "Epoch 15/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3520 - val_loss: 0.3672\n",
      "Epoch 16/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3513 - val_loss: 0.3685\n",
      "Epoch 17/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.3496 - val_loss: 0.3679\n",
      "Epoch 18/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.3481 - val_loss: 0.3675\n",
      "Epoch 19/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.3477 - val_loss: 0.3646\n",
      "Epoch 20/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.3462 - val_loss: 0.3656\n",
      "Epoch 21/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3456 - val_loss: 0.3651\n",
      "Epoch 22/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3444 - val_loss: 0.3639\n",
      "Epoch 23/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3431 - val_loss: 0.3626\n",
      "Epoch 24/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.3420 - val_loss: 0.3624\n",
      "Epoch 25/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3420 - val_loss: 0.3610\n",
      "Epoch 26/200\n",
      "579/579 [==============================] - 6s 10ms/step - loss: 0.3410 - val_loss: 0.3627\n",
      "Epoch 27/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.3399 - val_loss: 0.3582\n",
      "Epoch 28/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3398 - val_loss: 0.3631\n",
      "Epoch 29/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3396 - val_loss: 0.3647\n",
      "Epoch 30/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.3383 - val_loss: 0.3603\n",
      "Epoch 31/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3391 - val_loss: 0.3620\n",
      "Epoch 32/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3382 - val_loss: 0.3588\n",
      "Epoch 33/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3372 - val_loss: 0.3579\n",
      "Epoch 34/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3368 - val_loss: 0.3578\n",
      "Epoch 35/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3359 - val_loss: 0.3577\n",
      "Epoch 36/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3361 - val_loss: 0.3573\n",
      "Epoch 37/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3349 - val_loss: 0.3535\n",
      "Epoch 38/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.3339 - val_loss: 0.3578\n",
      "Epoch 39/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.3339 - val_loss: 0.3559\n",
      "Epoch 40/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3330 - val_loss: 0.3543\n",
      "Epoch 41/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3326 - val_loss: 0.3545\n",
      "Epoch 42/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3326 - val_loss: 0.3562\n",
      "Epoch 43/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3318 - val_loss: 0.3543\n",
      "Epoch 44/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3316 - val_loss: 0.3558\n",
      "Epoch 45/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.3310 - val_loss: 0.3551\n",
      "Epoch 46/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.3312 - val_loss: 0.3531\n",
      "Epoch 47/200\n",
      "579/579 [==============================] - 6s 10ms/step - loss: 0.3302 - val_loss: 0.3535\n",
      "Epoch 48/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.3300 - val_loss: 0.3516\n",
      "Epoch 49/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.3292 - val_loss: 0.3539\n",
      "Epoch 50/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.3294 - val_loss: 0.3495\n",
      "Epoch 51/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.3285 - val_loss: 0.3580\n",
      "Epoch 52/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3288 - val_loss: 0.3542\n",
      "Epoch 53/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3285 - val_loss: 0.3551\n",
      "Epoch 54/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.3277 - val_loss: 0.3510\n",
      "Epoch 55/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3272 - val_loss: 0.3527\n",
      "Epoch 56/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3273 - val_loss: 0.3521\n",
      "Epoch 57/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3265 - val_loss: 0.3513\n",
      "Epoch 58/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3264 - val_loss: 0.3494\n",
      "Epoch 59/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3261 - val_loss: 0.3516\n",
      "Epoch 60/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3251 - val_loss: 0.3537\n",
      "Epoch 61/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3253 - val_loss: 0.3496\n",
      "Epoch 62/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3239 - val_loss: 0.3528\n",
      "Epoch 63/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3245 - val_loss: 0.3511\n",
      "Epoch 64/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.3244 - val_loss: 0.3508\n",
      "Epoch 65/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.3238 - val_loss: 0.3495\n",
      "Epoch 66/200\n",
      "579/579 [==============================] - 6s 10ms/step - loss: 0.3237 - val_loss: 0.3544\n",
      "Epoch 67/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.3231 - val_loss: 0.3481\n",
      "Epoch 68/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.3224 - val_loss: 0.3521\n",
      "Epoch 69/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3226 - val_loss: 0.3497\n",
      "Epoch 70/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.3228 - val_loss: 0.3484\n",
      "Epoch 71/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3214 - val_loss: 0.3488\n",
      "Epoch 72/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3219 - val_loss: 0.3497\n",
      "Epoch 73/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3213 - val_loss: 0.3490\n",
      "Epoch 74/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3212 - val_loss: 0.3511\n",
      "Epoch 75/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3213 - val_loss: 0.3603\n",
      "Epoch 76/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3206 - val_loss: 0.3508\n",
      "Epoch 77/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3205 - val_loss: 0.3504\n",
      "Epoch 78/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3202 - val_loss: 0.3497\n",
      "Epoch 79/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3198 - val_loss: 0.3507\n",
      "Epoch 80/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3193 - val_loss: 0.3492\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3202 - val_loss: 0.3534\n",
      "Epoch 82/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3199 - val_loss: 0.3512\n",
      "Epoch 83/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3195 - val_loss: 0.3517\n",
      "Epoch 84/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3191 - val_loss: 0.3514\n",
      "Epoch 85/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3194 - val_loss: 0.3473\n",
      "Epoch 86/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3179 - val_loss: 0.3509\n",
      "Epoch 87/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3185 - val_loss: 0.3522\n",
      "Epoch 88/200\n",
      "579/579 [==============================] - 4s 8ms/step - loss: 0.3184 - val_loss: 0.3497\n",
      "Epoch 89/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3174 - val_loss: 0.3498\n",
      "Epoch 90/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3182 - val_loss: 0.3505\n",
      "Epoch 91/200\n",
      "579/579 [==============================] - 4s 8ms/step - loss: 0.3173 - val_loss: 0.3523\n",
      "Epoch 92/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3180 - val_loss: 0.3510\n",
      "Epoch 93/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3179 - val_loss: 0.3482\n",
      "Epoch 94/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3177 - val_loss: 0.3485\n",
      "Epoch 95/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3168 - val_loss: 0.3544\n",
      "Epoch 96/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3177 - val_loss: 0.3482\n",
      "Epoch 97/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3168 - val_loss: 0.3499\n",
      "Epoch 98/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.3170 - val_loss: 0.3499\n",
      "Epoch 99/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.3173 - val_loss: 0.3494\n",
      "Epoch 100/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.3172 - val_loss: 0.3488\n",
      "Epoch 101/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3163 - val_loss: 0.3499\n",
      "Epoch 102/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3162 - val_loss: 0.3501\n",
      "Epoch 103/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3164 - val_loss: 0.3518\n",
      "Epoch 104/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3164 - val_loss: 0.3491\n",
      "Epoch 105/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.3166 - val_loss: 0.3492\n",
      "Epoch 106/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3166 - val_loss: 0.3472\n",
      "Epoch 107/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3158 - val_loss: 0.3476\n",
      "Epoch 108/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3152 - val_loss: 0.3398\n",
      "Epoch 109/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3082 - val_loss: 0.3428\n",
      "Epoch 110/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3080 - val_loss: 0.3403\n",
      "Epoch 111/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3082 - val_loss: 0.3380\n",
      "Epoch 112/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.3076 - val_loss: 0.3393\n",
      "Epoch 113/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3079 - val_loss: 0.3393\n",
      "Epoch 114/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.3075 - val_loss: 0.3437\n",
      "Epoch 115/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3085 - val_loss: 0.3439\n",
      "Epoch 116/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3074 - val_loss: 0.3438\n",
      "Epoch 117/200\n",
      "579/579 [==============================] - 4s 8ms/step - loss: 0.3076 - val_loss: 0.3395\n",
      "Epoch 118/200\n",
      "579/579 [==============================] - 4s 8ms/step - loss: 0.3071 - val_loss: 0.3374\n",
      "Epoch 119/200\n",
      "579/579 [==============================] - 4s 8ms/step - loss: 0.3069 - val_loss: 0.3403\n",
      "Epoch 120/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3069 - val_loss: 0.3396\n",
      "Epoch 121/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3066 - val_loss: 0.3418\n",
      "Epoch 122/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3065 - val_loss: 0.3393\n",
      "Epoch 123/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3070 - val_loss: 0.3392\n",
      "Epoch 124/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3029 - val_loss: 0.3354\n",
      "Epoch 125/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.3023 - val_loss: 0.3334\n",
      "Epoch 126/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3028 - val_loss: 0.3334\n",
      "Epoch 127/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3024 - val_loss: 0.3359\n",
      "Epoch 128/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3028 - val_loss: 0.3381\n",
      "Epoch 129/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.3015 - val_loss: 0.3375\n",
      "Epoch 130/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3022 - val_loss: 0.3377\n",
      "Epoch 131/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.3018 - val_loss: 0.3338\n",
      "Epoch 132/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3022 - val_loss: 0.3339\n",
      "Epoch 133/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3021 - val_loss: 0.3329\n",
      "Epoch 134/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3017 - val_loss: 0.3329\n",
      "Epoch 135/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3014 - val_loss: 0.3325\n",
      "Epoch 136/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3017 - val_loss: 0.3323\n",
      "Epoch 137/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3005 - val_loss: 0.3353\n",
      "Epoch 138/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3000 - val_loss: 0.3345\n",
      "Epoch 139/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.2998 - val_loss: 0.3333\n",
      "Epoch 140/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3003 - val_loss: 0.3337\n",
      "Epoch 141/200\n",
      "579/579 [==============================] - 4s 8ms/step - loss: 0.2999 - val_loss: 0.3326\n",
      "Epoch 142/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.2998 - val_loss: 0.3309\n",
      "Epoch 143/200\n",
      "579/579 [==============================] - 4s 8ms/step - loss: 0.2997 - val_loss: 0.3329\n",
      "Epoch 144/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.2997 - val_loss: 0.3322\n",
      "Epoch 145/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.2996 - val_loss: 0.3323\n",
      "Epoch 146/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.3001 - val_loss: 0.3331\n",
      "Epoch 147/200\n",
      "579/579 [==============================] - 4s 8ms/step - loss: 0.2994 - val_loss: 0.3313\n",
      "Epoch 148/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.2988 - val_loss: 0.3333\n",
      "Epoch 149/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.2995 - val_loss: 0.3360\n",
      "Epoch 150/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.2993 - val_loss: 0.3347\n",
      "Epoch 151/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.2993 - val_loss: 0.3310\n",
      "Epoch 152/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.2993 - val_loss: 0.3378\n",
      "Epoch 153/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.2992 - val_loss: 0.3359\n",
      "Epoch 154/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.2990 - val_loss: 0.3339\n",
      "Epoch 155/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.2992 - val_loss: 0.3317\n",
      "Epoch 156/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.2989 - val_loss: 0.3329\n",
      "Epoch 157/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.2990 - val_loss: 0.3356\n",
      "Epoch 158/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.2990 - val_loss: 0.3323\n",
      "Epoch 159/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.2986 - val_loss: 0.3322\n",
      "Epoch 160/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.2987 - val_loss: 0.3364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.2985 - val_loss: 0.3315\n",
      "Epoch 162/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.2982 - val_loss: 0.3323\n",
      "Epoch 163/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.2986 - val_loss: 0.3306\n",
      "Epoch 164/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.2983 - val_loss: 0.3327\n",
      "Epoch 165/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.2982 - val_loss: 0.3339\n",
      "Epoch 166/200\n",
      "579/579 [==============================] - 4s 8ms/step - loss: 0.2980 - val_loss: 0.3304\n",
      "Epoch 167/200\n",
      "579/579 [==============================] - 4s 8ms/step - loss: 0.2979 - val_loss: 0.3340\n",
      "Epoch 168/200\n",
      "579/579 [==============================] - 4s 8ms/step - loss: 0.2979 - val_loss: 0.3324\n",
      "Epoch 169/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.2980 - val_loss: 0.3323\n",
      "Epoch 170/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.2976 - val_loss: 0.3314\n",
      "Epoch 171/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.2980 - val_loss: 0.3326\n",
      "Epoch 172/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.2979 - val_loss: 0.3304\n",
      "Epoch 173/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.2979 - val_loss: 0.3293\n",
      "Epoch 174/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.2972 - val_loss: 0.3348\n",
      "Epoch 175/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.2979 - val_loss: 0.3305\n",
      "Epoch 176/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.2969 - val_loss: 0.3306\n",
      "Epoch 177/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.2979 - val_loss: 0.3291\n",
      "Epoch 178/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.2967 - val_loss: 0.3328\n",
      "Epoch 179/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.2967 - val_loss: 0.3294\n",
      "Epoch 180/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.2969 - val_loss: 0.3341\n",
      "Epoch 181/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.2968 - val_loss: 0.3364\n",
      "Epoch 182/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.2969 - val_loss: 0.3298\n",
      "Epoch 183/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.2970 - val_loss: 0.3319\n",
      "Epoch 184/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.2967 - val_loss: 0.3308\n",
      "Epoch 185/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.2969 - val_loss: 0.3320\n",
      "Epoch 186/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.2968 - val_loss: 0.3320\n",
      "Epoch 187/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.2963 - val_loss: 0.3311\n",
      "Epoch 188/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.2966 - val_loss: 0.3344\n",
      "Epoch 189/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.2972 - val_loss: 0.3324\n",
      "Epoch 190/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.2964 - val_loss: 0.3316\n",
      "Epoch 191/200\n",
      "579/579 [==============================] - 5s 8ms/step - loss: 0.2962 - val_loss: 0.3296\n",
      "Epoch 192/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.2961 - val_loss: 0.3321\n",
      "Epoch 193/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.2962 - val_loss: 0.3375\n",
      "Epoch 194/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.2954 - val_loss: 0.3334\n",
      "Epoch 195/200\n",
      "579/579 [==============================] - 6s 10ms/step - loss: 0.2956 - val_loss: 0.3330\n",
      "Epoch 196/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.2956 - val_loss: 0.3309\n",
      "Epoch 197/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.2963 - val_loss: 0.3301\n",
      "Epoch 198/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.2960 - val_loss: 0.3303\n",
      "Epoch 199/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.2953 - val_loss: 0.3317\n",
      "Epoch 200/200\n",
      "579/579 [==============================] - 5s 9ms/step - loss: 0.2953 - val_loss: 0.3307\n",
      "CPU times: user 14min 48s, sys: 5min 51s, total: 20min 39s\n",
      "Wall time: 16min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = dnn_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    verbose=0, epochs=200,workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "published-peter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history)\n",
    "plt.ylim(0.2,0.6)\n",
    "plt.savefig(\"dnn_loss.pdf\",format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "fatal-minnesota",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = dnn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "current-bridal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test samples: 9916\n",
      "correct: 2297 fraction: 0.23164582492940702\n"
     ]
    }
   ],
   "source": [
    "# ricategorise predictions\n",
    "cat_pred = np.zeros_like(pred)\n",
    "correct = 0\n",
    "for n,p in enumerate(pred):\n",
    "    if(all([int(i) for i in p] ==  y_test[n])):\n",
    "        correct += 1\n",
    "    #print(all([int(i) for i in p] ==  y_test[n]))\n",
    "    cat_pred[n,:] = [round(i) for i in p]\n",
    "print(\"test samples:\",len(y_test))\n",
    "print(\"correct:\",correct,\"fraction:\", correct/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "velvet-federation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: dnn_predictor.krs/assets\n"
     ]
    }
   ],
   "source": [
    "dnn_model.save(\"dnn_predictor.krs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "alpine-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "radical-thermal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2574760414427641"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.r2_score(pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-lancaster",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
